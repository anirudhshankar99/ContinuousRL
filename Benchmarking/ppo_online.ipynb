{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import gymnasium as gym\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils import tensorboard\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mish(input):\n",
    "    return input * torch.tanh(F.softplus(input))\n",
    "\n",
    "class Mish(nn.Module):\n",
    "    def __init__(self): super().__init__()\n",
    "    def forward(self, input): return mish(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function to convert numpy arrays to tensors\n",
    "def t(x): return torch.from_numpy(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actor module, categorical actions only\n",
    "class Actor(nn.Module):\n",
    "    def __init__(self, state_dim, n_actions, activation=nn.Tanh):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(state_dim, 64),\n",
    "            activation(),\n",
    "            nn.Linear(64, 32),\n",
    "            activation(),\n",
    "            nn.Linear(32, n_actions),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Critic module\n",
    "class Critic(nn.Module):\n",
    "    def __init__(self, state_dim, activation=nn.Tanh):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(state_dim, 64),\n",
    "            activation(),\n",
    "            nn.Linear(64, 32),\n",
    "            activation(),\n",
    "            nn.Linear(32, 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x750a1a590610>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config\n",
    "state_dim = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "actor = Actor(state_dim, n_actions, activation=Mish)\n",
    "critic = Critic(state_dim, activation=Mish)\n",
    "adam_actor = torch.optim.Adam(actor.parameters(), lr=3e-4)\n",
    "adam_critic = torch.optim.Adam(critic.parameters(), lr=1e-3)\n",
    "\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_grad_norm_(module, max_grad_norm):\n",
    "    nn.utils.clip_grad_norm_([p for g in module.param_groups for p in g[\"params\"]], max_grad_norm)\n",
    "\n",
    "def policy_loss(old_log_prob, log_prob, advantage, eps):\n",
    "    ratio = (log_prob - old_log_prob).exp()\n",
    "    clipped = torch.clamp(ratio, 1-eps, 1+eps)*advantage\n",
    "    \n",
    "    m = torch.min(ratio*advantage, clipped)\n",
    "    return -m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/800 [00:00<?, ?it/s]/home/a.shankar/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1739: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n",
      "  0%|          | 1/800 [00:00<03:06,  4.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0271, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9866, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0155, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9889, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9775, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0272, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0151, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0017, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9879, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0148, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9789, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9660, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9528, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9392, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2088, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9803, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0132, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9826, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0093, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9844, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0064, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9927, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9788, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9652, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9520, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9392, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9269, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9150, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/800 [00:00<03:15,  4.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1047, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0975, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0865, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0729, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9158, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0731, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0586, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0433, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9377, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9237, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8528, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0405, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0221, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9662, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9548, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0308, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9570, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 3/800 [00:00<03:09,  4.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0277, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9586, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0252, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0093, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9743, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0066, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9764, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9641, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0186, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9640, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0180, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9636, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9513, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0324, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0189, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9606, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0188, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9596, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9466, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0337, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0210, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9543, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0217, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9519, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9382, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9252, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6719, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9779, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9655, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0124, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9656, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0109, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9949, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9802, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9922, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9765, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9615, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0127, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9561, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0164, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0052, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9623, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9476, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9337, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9206, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5387, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9679, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0046, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9889, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9794, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 6/800 [00:00<01:31,  8.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9655, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9520, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9390, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9265, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9142, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0650, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0565, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0452, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0318, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9221, grad_fn=<MeanBackward0>)\n",
      "tensor(0.3350, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9514, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0123, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9922, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9720, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9897, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9652, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9948, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9810, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9671, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9533, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0065, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9901, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9724, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9544, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0020, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9870, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9718, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9811, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9712, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9560, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9413, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9270, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9131, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0450, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0359, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9064, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8921, grad_fn=<MeanBackward0>)\n",
      "tensor(0.2664, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9443, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0027, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9841, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9614, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9816, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9629, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9443, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0047, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9861, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9667, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9472, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9933, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9422, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9956, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9369, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9979, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9310, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9111, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0175, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9009, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0987, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9789, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9558, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9780, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9545, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9776, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9527, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9775, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9581, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9727, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9568, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9374, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9185, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0218, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9137, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8958, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0501, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0296, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0067, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9239, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 11/800 [00:01<00:55, 14.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9051, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0288, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9029, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8848, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0534, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0329, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8963, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8780, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0560, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8728, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8555, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8393, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1008, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0536, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9597, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9368, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9814, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9295, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9847, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9218, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8984, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0087, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8853, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8620, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0023, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9041, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8838, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8638, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0675, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0410, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8778, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0393, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8764, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0384, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8742, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0382, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8711, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0390, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8667, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8419, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8188, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0001, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9809, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9499, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9183, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9850, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9118, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8800, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8491, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0566, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8318, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0640, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0390, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8350, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8023, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7709, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0002, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8775, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8415, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8062, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1145, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7837, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1255, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0938, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0573, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8170, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7778, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0988, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0638, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7930, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7521, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7131, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0024, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0269, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8572, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0308, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9863, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8960, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 14/800 [00:01<00:49, 15.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9849, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8972, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9832, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9369, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9486, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9303, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8851, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0073, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8732, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8302, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0691, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0332, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9940, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8818, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8346, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0478, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4828, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9376, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8937, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9833, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8980, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9803, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9022, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9770, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9061, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9735, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9100, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8655, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0211, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8642, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8200, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7770, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7351, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6939, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6531, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6124, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2923, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2682, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0250, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7939, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7452, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6977, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6515, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2637, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6207, grad_fn=<MeanBackward0>)\n",
      "tensor(1.2661, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5908, grad_fn=<MeanBackward0>)\n",
      "tensor(0.5477, grad_fn=<MeanBackward0>)\n",
      "tensor(0.1178, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9413, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8852, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8334, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7860, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7424, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7018, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6632, grad_fn=<MeanBackward0>)\n",
      "tensor(0.0099, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9118, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9340, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9302, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8652, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7993, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7345, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1318, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7193, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1354, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0636, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7665, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0641, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7558, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0667, grad_fn=<MeanBackward0>)\n",
      "tensor(0.7415, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6640, grad_fn=<MeanBackward0>)\n",
      "tensor(1.1435, grad_fn=<MeanBackward0>)\n",
      "tensor(0.6357, grad_fn=<MeanBackward0>)\n",
      "tensor(0.4321, grad_fn=<MeanBackward0>)\n",
      "tensor(0.9582, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8839, grad_fn=<MeanBackward0>)\n",
      "tensor(0.8018, grad_fn=<MeanBackward0>)\n",
      "tensor(1.0603, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "episode_rewards = []\n",
    "gamma = 0.98\n",
    "eps = 0.2\n",
    "log = False\n",
    "if log:\n",
    "    w = tensorboard.SummaryWriter('../runs/x')\n",
    "s = 0\n",
    "max_grad_norm = 0.5\n",
    "\n",
    "for i in tqdm(range(800)):\n",
    "    prev_prob_act = None\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    state, _ = env.reset()\n",
    "\n",
    "\n",
    "    while not done:\n",
    "        s += 1\n",
    "        probs = actor(t(state))\n",
    "        dist = torch.distributions.Categorical(probs=probs)\n",
    "        action = dist.sample()\n",
    "        prob_act = dist.log_prob(action)\n",
    "        \n",
    "        next_state, reward, done, _, info = env.step(action.detach().numpy())\n",
    "        advantage = reward + (1-done)*gamma*critic(t(next_state)) - critic(t(state))\n",
    "        \n",
    "        if log:\n",
    "            w.add_scalar(\"loss/advantage\", advantage, global_step=s)\n",
    "            w.add_scalar(\"actions/action_0_prob\", dist.probs[0], global_step=s)\n",
    "            w.add_scalar(\"actions/action_1_prob\", dist.probs[1], global_step=s)\n",
    "        \n",
    "        total_reward += reward\n",
    "        state = next_state\n",
    "        \n",
    "        if prev_prob_act:\n",
    "            actor_loss = policy_loss(prev_prob_act.detach(), prob_act, advantage.detach(), eps)\n",
    "            if log:\n",
    "                w.add_scalar(\"loss/actor_loss\", actor_loss, global_step=s)\n",
    "            adam_actor.zero_grad()\n",
    "            actor_loss.backward()\n",
    "            # clip_grad_norm_(adam_actor, max_grad_norm)\n",
    "            if log:\n",
    "                w.add_histogram(\"gradients/actor\",\n",
    "                                torch.cat([p.grad.view(-1) for p in actor.parameters()]), global_step=s)\n",
    "            adam_actor.step()\n",
    "\n",
    "            critic_loss = advantage.pow(2).mean()\n",
    "            if log:\n",
    "                w.add_scalar(\"loss/critic_loss\", critic_loss, global_step=s)\n",
    "            adam_critic.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            # clip_grad_norm_(adam_critic, max_grad_norm)\n",
    "            if log:\n",
    "                w.add_histogram(\"gradients/critic\",\n",
    "                             torch.cat([p.data.view(-1) for p in critic.parameters()]), global_step=s)\n",
    "            adam_critic.step()\n",
    "        \n",
    "        prev_prob_act = prob_act\n",
    "    \n",
    "    if log:\n",
    "        w.add_scalar(\"reward/episode_reward\", total_reward, global_step=i)\n",
    "    episode_rewards.append(total_reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
